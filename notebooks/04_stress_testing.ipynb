{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8afdca",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb7ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_PATH   = PROJECT_ROOT / \"data_work\" / \"loans_fe.parquet\"   # adjust if name differs\n",
    "RES_DIR     = PROJECT_ROOT / \"results\"\n",
    "FIG_DIR     = RES_DIR / \"figures\"\n",
    "MODEL_DIR   = RES_DIR / \"models\"\n",
    "\n",
    "RES_DIR.mkdir(exist_ok=True, parents=True)\n",
    "FIG_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1ecd27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/binodtandan/UNT Research/ai_stress_testing\n",
      "Data path: /Users/binodtandan/UNT Research/ai_stress_testing/data_work/loans_fe.parquet\n",
      "Model dir: /Users/binodtandan/UNT Research/ai_stress_testing/results/models\n"
     ]
    }
   ],
   "source": [
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Data path:\", DATA_PATH)\n",
    "print(\"Model dir:\", MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c5c8854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (2258953, 33)\n",
      "['issue_q_start', 'loan_amnt', 'term_m', 'int_rate', 'dti', 'fico', 'emp_length', 'GDPC1', 'UNRATE', 'CPIAUCSL', 'FEDFUNDS', 'target', 'log_annual_inc', 'grade_b', 'grade_c', 'grade_d', 'grade_e', 'grade_f', 'home_ownership_mortgage', 'home_ownership_own'] ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Load engineered dataset\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(df.columns.tolist()[:20], \"...\")\n",
    "\n",
    "TARGET   = \"target\"\n",
    "TIME_COL = \"issue_q_start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc9f918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1764843, 31)  Test shape: (494110, 31)\n",
      "Train default rate: 0.14756893389383646  Test default rate: 0.01791706300216551\n"
     ]
    }
   ],
   "source": [
    "# 2) Time-based train/test split (same logic as in 03_model_training.ipynb)\n",
    "split_date = pd.Timestamp(\"2017-12-31\")\n",
    "train_df = df[df[TIME_COL] <= split_date].copy()\n",
    "test_df  = df[df[TIME_COL] >  split_date].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET, TIME_COL])\n",
    "y_train = train_df[TARGET].astype(int)\n",
    "X_test  = test_df.drop(columns=[TARGET, TIME_COL])\n",
    "y_test  = test_df[TARGET].astype(int)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n",
    "print(\"Train default rate:\", y_train.mean(), \" Test default rate:\", y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a38e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded logistic model from /Users/binodtandan/UNT Research/ai_stress_testing/results/models/logistic_balanced.joblib\n"
     ]
    }
   ],
   "source": [
    "# 3) Load trained models (from 03_model_training.ipynb)\n",
    "logreg_path = MODEL_DIR / \"logistic_balanced.joblib\"\n",
    "tree_path   = MODEL_DIR / \"tree_balanced.joblib\"\n",
    "\n",
    "logreg = joblib.load(logreg_path)\n",
    "print(\"Loaded logistic model from\", logreg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e27e5524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_pd': 0.16906894089845018,\n",
       " 'p50_pd': 0.14116718042866067,\n",
       " 'p90_pd': 0.33145939305832345,\n",
       " 'p99_pd': 0.54159379087249}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Compute baseline PDs on 2018 test set (this is our reference scenario)\n",
    "proba_lr_baseline = logreg.predict_proba(X_test)[:, 1]\n",
    "baseline_summary = {\n",
    "    \"mean_pd\": float(proba_lr_baseline.mean()),\n",
    "    \"p50_pd\":  float(np.quantile(proba_lr_baseline, 0.5)),\n",
    "    \"p90_pd\":  float(np.quantile(proba_lr_baseline, 0.9)),\n",
    "    \"p99_pd\":  float(np.quantile(proba_lr_baseline, 0.99)),\n",
    "}\n",
    "baseline_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa173cbc",
   "metadata": {},
   "source": [
    "## Step 2: Define & Apply Data-Driven Macro Stress Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "253dd69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDPC1</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "      <th>UNRATE_delta_qoq</th>\n",
       "      <th>FEDFUNDS_delta_qoq</th>\n",
       "      <th>GDPC1_delta_qoq</th>\n",
       "      <th>inflation_qoq</th>\n",
       "      <th>real_rate_qoq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>17953.974</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>234.162667</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>-0.060440</td>\n",
       "      <td>-0.035714</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>0.068379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>18782.243</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>236.960000</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>-0.041958</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.091345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>19197.938</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>240.607333</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>-0.027211</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.121902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>19882.352</td>\n",
       "      <td>5.433333</td>\n",
       "      <td>247.238333</td>\n",
       "      <td>1.203333</td>\n",
       "      <td>-0.013072</td>\n",
       "      <td>0.202216</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.154176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>20276.154</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>251.686333</td>\n",
       "      <td>1.923333</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.007955</td>\n",
       "      <td>0.190550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GDPC1    UNRATE    CPIAUCSL  FEDFUNDS  UNRATE_delta_qoq  \\\n",
       "0.10  17953.974  3.833333  234.162667  0.093333         -0.060440   \n",
       "0.25  18782.243  4.166667  236.960000  0.136667         -0.041958   \n",
       "0.50  19197.938  4.900000  240.607333  0.396667         -0.027211   \n",
       "0.75  19882.352  5.433333  247.238333  1.203333         -0.013072   \n",
       "0.90  20276.154  6.933333  251.686333  1.923333          0.006803   \n",
       "\n",
       "      FEDFUNDS_delta_qoq  GDPC1_delta_qoq  inflation_qoq  real_rate_qoq  \n",
       "0.10           -0.035714         0.001845      -0.000621       0.068379  \n",
       "0.25            0.062500         0.004002       0.001585       0.091345  \n",
       "0.50            0.134454         0.005795       0.004245       0.121902  \n",
       "0.75            0.202216         0.007885       0.006348       0.154176  \n",
       "0.90            0.555556         0.011270       0.007955       0.190550  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Macro level features (levels)\n",
    "macro_cols = [\"GDPC1\", \"UNRATE\", \"CPIAUCSL\", \"FEDFUNDS\"]\n",
    "\n",
    "# Macro dynamics / deltas (already engineered)\n",
    "delta_cols = [\"UNRATE_delta_qoq\", \"FEDFUNDS_delta_qoq\",\n",
    "              \"GDPC1_delta_qoq\", \"inflation_qoq\", \"real_rate_qoq\"]\n",
    "\n",
    "all_macro_feats = macro_cols + delta_cols\n",
    "\n",
    "# Use the full history to derive empirical quantiles\n",
    "macro_quantiles = df[all_macro_feats].quantile([0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "macro_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85262e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'scenario': 'baseline_actual'},\n",
       " {'scenario': 'mild_adverse',\n",
       "  'GDPC1': 19882.352,\n",
       "  'UNRATE': 5.433333333333334,\n",
       "  'CPIAUCSL': 247.23833333333334,\n",
       "  'FEDFUNDS': 1.2033333333333334,\n",
       "  'UNRATE_delta_qoq': -0.013071895424836777,\n",
       "  'FEDFUNDS_delta_qoq': 0.2022160664819943,\n",
       "  'GDPC1_delta_qoq': 0.00788524130554702,\n",
       "  'inflation_qoq': 0.006347825364148241,\n",
       "  'real_rate_qoq': 0.15417567635744467},\n",
       " {'scenario': 'severe_adverse',\n",
       "  'GDPC1': 20276.154,\n",
       "  'UNRATE': 6.933333333333334,\n",
       "  'CPIAUCSL': 251.68633333333332,\n",
       "  'FEDFUNDS': 1.9233333333333331,\n",
       "  'UNRATE_delta_qoq': 0.006802721088435604,\n",
       "  'FEDFUNDS_delta_qoq': 0.5555555555555556,\n",
       "  'GDPC1_delta_qoq': 0.011270466267692791,\n",
       "  'inflation_qoq': 0.007955306776687543,\n",
       "  'real_rate_qoq': 0.1905504756186524}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper to build a scenario vector from quantiles\n",
    "def make_scenario(name, level_q, delta_q):\n",
    "    \"\"\"\n",
    "    name: string label for scenario\n",
    "    level_q: which quantile to use for macro levels  (GDPC1, UNRATE, CPI, FEDFUNDS)\n",
    "    delta_q: which quantile to use for macro deltas (UNRATE_delta_qoq, etc.)\n",
    "    \"\"\"\n",
    "    s = {\"scenario\": name}\n",
    "    # Levels\n",
    "    for col in macro_cols:\n",
    "        s[col] = float(macro_quantiles.loc[level_q, col])\n",
    "    # Deltas\n",
    "    for col in delta_cols:\n",
    "        s[col] = float(macro_quantiles.loc[delta_q, col])\n",
    "    return s\n",
    "\n",
    "scenarios = []\n",
    "\n",
    "# 0) Baseline (reference) = actual 2018 macro, i.e. \"no shock\"\n",
    "#    We already have baseline PDs from proba_lr_baseline.\n",
    "#    We'll still store it in the summary table below as \"baseline_actual\".\n",
    "scenarios.append({\"scenario\": \"baseline_actual\"})  # placeholder; no override\n",
    "\n",
    "# 1) Mild Adverse: moderately bad macro conditions\n",
    "#    - High unemployment (75th)\n",
    "#    - Low GDP (25th)\n",
    "#    - Higher rates & inflation (75th)\n",
    "scenarios.append(make_scenario(\"mild_adverse\", level_q=0.75, delta_q=0.75))\n",
    "\n",
    "# 2) Severe Adverse: very stressed macro conditions\n",
    "#    - Very high unemployment (90th)\n",
    "#    - Very low GDP (10th)\n",
    "#    - Strong rate shock & inflation dynamics (90th deltas)\n",
    "scenarios.append(make_scenario(\"severe_adverse\", level_q=0.90, delta_q=0.90))\n",
    "\n",
    "scenarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdf155ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>mean_pd</th>\n",
       "      <th>p50_pd</th>\n",
       "      <th>p90_pd</th>\n",
       "      <th>p99_pd</th>\n",
       "      <th>uplift_vs_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline_actual</td>\n",
       "      <td>0.169069</td>\n",
       "      <td>0.141167</td>\n",
       "      <td>0.331459</td>\n",
       "      <td>0.541594</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mild_adverse</td>\n",
       "      <td>0.195667</td>\n",
       "      <td>0.185901</td>\n",
       "      <td>0.317873</td>\n",
       "      <td>0.437739</td>\n",
       "      <td>15.731878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>severe_adverse</td>\n",
       "      <td>0.066860</td>\n",
       "      <td>0.060201</td>\n",
       "      <td>0.115610</td>\n",
       "      <td>0.179246</td>\n",
       "      <td>-60.453837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          scenario   mean_pd    p50_pd    p90_pd    p99_pd  uplift_vs_baseline\n",
       "0  baseline_actual  0.169069  0.141167  0.331459  0.541594            0.000000\n",
       "1     mild_adverse  0.195667  0.185901  0.317873  0.437739           15.731878\n",
       "2   severe_adverse  0.066860  0.060201  0.115610  0.179246          -60.453837"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Apply scenarios and compute PD distributions ===================\n",
    "\n",
    "stress_records = []\n",
    "\n",
    "# Baseline reference (no macro override; just use proba_lr_baseline)\n",
    "baseline_mean = float(proba_lr_baseline.mean())\n",
    "baseline_p50  = float(np.quantile(proba_lr_baseline, 0.5))\n",
    "baseline_p90  = float(np.quantile(proba_lr_baseline, 0.9))\n",
    "baseline_p99  = float(np.quantile(proba_lr_baseline, 0.99))\n",
    "\n",
    "stress_records.append({\n",
    "    \"scenario\": \"baseline_actual\",\n",
    "    \"mean_pd\": baseline_mean,\n",
    "    \"p50_pd\":  baseline_p50,\n",
    "    \"p90_pd\":  baseline_p90,\n",
    "    \"p99_pd\":  baseline_p99,\n",
    "    \"uplift_vs_baseline\": 0.0  # by definition\n",
    "})\n",
    "\n",
    "# Function to override macro features and recompute PDs\n",
    "def apply_macro_scenario(X, scen_dict):\n",
    "    X_new = X.copy()\n",
    "    # For placeholder baseline_actual, we don't touch X\n",
    "    if scen_dict.get(\"scenario\") == \"baseline_actual\":\n",
    "        return X_new\n",
    "    for col in all_macro_feats:\n",
    "        if col in scen_dict:\n",
    "            X_new[col] = scen_dict[col]\n",
    "    return X_new\n",
    "\n",
    "for scen in scenarios:\n",
    "    name = scen[\"scenario\"]\n",
    "    if name == \"baseline_actual\":\n",
    "        continue  # already handled above\n",
    "\n",
    "    X_scen = apply_macro_scenario(X_test, scen)\n",
    "    proba_scen = logreg.predict_proba(X_scen)[:, 1]\n",
    "\n",
    "    mean_pd = float(proba_scen.mean())\n",
    "    p50_pd  = float(np.quantile(proba_scen, 0.5))\n",
    "    p90_pd  = float(np.quantile(proba_scen, 0.9))\n",
    "    p99_pd  = float(np.quantile(proba_scen, 0.99))\n",
    "\n",
    "    uplift = (mean_pd / baseline_mean - 1.0) * 100.0 if baseline_mean > 0 else np.nan\n",
    "\n",
    "    stress_records.append({\n",
    "        \"scenario\": name,\n",
    "        \"mean_pd\": mean_pd,\n",
    "        \"p50_pd\":  p50_pd,\n",
    "        \"p90_pd\":  p90_pd,\n",
    "        \"p99_pd\":  p99_pd,\n",
    "        \"uplift_vs_baseline\": uplift\n",
    "    })\n",
    "\n",
    "stress_df = pd.DataFrame(stress_records)\n",
    "stress_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96cef66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved stress scenario summary to: /Users/binodtandan/UNT Research/ai_stress_testing/results/stress_summary.csv\n"
     ]
    }
   ],
   "source": [
    "out_path = RES_DIR / \"stress_summary.csv\"\n",
    "stress_df.to_csv(out_path, index=False)\n",
    "print(\"Saved stress scenario summary to:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4baed6b",
   "metadata": {},
   "source": [
    "## Step 3: Define Fed Macro Stress Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === FED 2018 SCENARIOS: manual table =======================================\n",
    "\n",
    "# fed_rows = [\n",
    "\n",
    "#     # ---- Baseline ----\n",
    "#     {\"scenario\": \"Fed_Baseline\", \"quarter\": \"2018Q1\", \"UNRATE\": 4.0 \"GDPC1\": 2.5 \"CPIAUCSL\": 2.1 \"FEDFUNDS\": 1.4},\n",
    "#     {\"scenario\": \"Fed_Baseline\", \"quarter\": \"2018Q2\", \"UNRATE\": 4.0 \"GDPC1\": 2.8 \"CPIAUCSL\": ..., \"FEDFUNDS\": ...},\n",
    "#     # ...\n",
    "#     # ---- Adverse ----\n",
    "#     # {\"scenario\": \"Fed_Adverse\", \"quarter\": \"2018Q1\", \"UNRATE\": ..., \"GDPC1\": ..., \"CPIAUCSL\": ..., \"FEDFUNDS\": ...},\n",
    "#     # ...\n",
    "#     # ---- Severely Adverse ----\n",
    "#     # {\"scenario\": \"Fed_Severe\", \"quarter\": \"2018Q1\", \"UNRATE\": ..., \"GDPC1\": ..., \"CPIAUCSL\": ..., \"FEDFUNDS\": ...},\n",
    "#     # ...\n",
    "# ]\n",
    "\n",
    "# fed_macro = pd.DataFrame(fed_rows)\n",
    "\n",
    "# if fed_macro.empty:\n",
    "#     print(\"⚠️ fed_macro is empty. Fill fed_rows with Fed scenario values from the PDF.\")\n",
    "# else:\n",
    "#     display(fed_macro.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8110e00f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34836ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad161052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f09e416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25cb2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16558399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
